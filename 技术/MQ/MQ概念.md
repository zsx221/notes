    MQ概述
    小结
    ●MQ, 消息队列，存储消息的中间件
    ●分布式系统通信两种方式: 直接远程调用和借助第三方完成间接通信
    ●发送方称为生产者, 接收方称为消费者
    
    1.2 MQ的优势和劣势
    优势:
    ●应用解耦
    ●削峰填谷
    ●异步提速
      
    劣势:
    ●系统复杂度提高       因为引入了mq，整个系统的复杂性就提高了，需要考虑的问题变多了
    ●系统可用性降低        引入mq，如果mq出问题，或者宕机，系统同样会发生问题
    ●一致性问题          引入mq，一个请求过来，如果四个系统去执行并一起返回结果，三个系统都执行完成了，但是剩下一个系统由于某种原因没有执行完成，
                        导致返回的结果是成功的，但实际上没有成功
    
    1.3 kafka、activemq、rabbitmq、rocketmq都有什么优点和缺点？
        activemq: 吞吐量万级 非常成熟，功能强犬，在业内大量的公司以及项目中都有应用偶尔会有较低概率丢失消息，
            而且现在社区以及国内应用都越来越少，官方社区现在地ActiveMQ 5.x 维护越来越少，而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用  
        rabbitmq：吞吐量万级  erlang 语言开发，性能极其好而且开源提供的管理界面非常棒，用起来很好用，在国内一些互联网公司近几年用rabbitmq也比较多一些
                    但是问题也是显而易见的，RabbitMQ 确实香吐量会低一些，这是因为他做的实现机制比较重。而且erlang 开发，国内没有几个公司有实力做erlang源，会有几率丢失消息
        rocketmq：吞吐量十万级 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障
                    日处理消息上百亿之多，可以做到大规模香吐性能也非常好分布式扩展也很方便，社区维扩还可以，可靠性和可用性都是ok 的，还可以支撑大规模的topic数量，支持复杂MQ业务场景
        kafka：   吞吐量十万级 特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的香吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展
                同时 kafka 最好是支撑较少的topic 数量即可，保证其超高香吐量，而且 kafka 唯的一点劣势是有可能消息重复消费
        问题小结：activemq不推荐使用，中小型公司建议使用rabbitmq，大型公司建议使用rocketmq，大数据领域使用kafka。
    1.4 引入消息队列之后该如何保证其高可用性？
        rabbitmq：(主从副本)
            1）单体模式
            2）普通集群模式：创建一个队列，只会在一个实例里面存在其实际数据，其他实例中存在的是元数据(元数据指的是队列的配置信息，标识了实际数据的位置)，
                如果消费者连接到其他实例时，此实例需要从那个实例拉取实际数据。
                （缺点1:可能会在rabbitmq集群内部产生大量的数据传输(由于队列只存在于一个实例内)    缺点2:可用性几乎没有什么保障，如果queue所在的节点岩机了，就导致那个queue的数据就丢失了，你就没法消费了）
            3)镜像集群模式：每个实例都会同步队列。拥有队列的元数据和实际数据，无论消费者到哪一个实例，都能消费队列里面的消息。
                (怎么开启，rabbit的管理控制台，新增一个策略，可以指定数据同步到所有节点，也可以同步到指定节点)
                缺点：一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重!
                    第二!这么玩儿，就没有扩展性可言了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue
        
        kafka：(分布式  ) ![kafka的高可用设计](技术/MQ/kafka的高可用设计.png "kafka的高可用设计")
    1.5 mq重复消费，如何保证消息的幂等性呢？
        (1)比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了,update 一下好吧
        (2)比如你是写 redis，那没问题了，反正每次都是 set，天然幂等性
        (3)比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，
            先根据这个 id 去比如redis 里查一下，之前消费过吗? 如果没有消费过，你就处理，然后这个id写 redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
        (4)还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为 kafka 消费者还没来得及提交offset
            重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据
    1.6 mq可能存在的数据丢失问题
        分别使用两种mq来回答问题：
        1、rabbitmq
            1）生产者出现丢失 写消息的过程中，消息都没到rabbitmq，在网络传输过程中就丢了；或者是消息到了rabbitmq，但是mq内部出错了。没有保存。
                方案一：使用mq的事务功能，如果生产者发送消息失败， 回滚并且开启重发机制。  因为事务是同步的，会导致生产者发送消息会阻塞等待你是成功还是失败。导致生产者发送消息的吞吐量降低
                方案二：(异步,不用等待)channel设置成confirm模式,使用回调机制，如果mq成功接收到你的消息，回调你的接口，告诉你的接口，这条消息接收成功，否则告诉你的接口重新发送。
            
            2）rabbitmq出现问题，自己丢掉了消息
                方案：设置持久化有两个步骤，第一个是创建 queue 的时候将其设置为持久化的，这样就可以保证 rabbitmg 持久化 queue 的元数据，但是不会持久化 queue 里的数据
                    第二个是发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 rabbitmq 就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行。
                        rabbitmq 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。
                        而且持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack了，所以哪怕是在持久化到磁盘之前，rabbitmq 挂了，数据丢了
                            生产者收不到 ack，你也是可以自己重发的。

            3)消费者出现丢失  开启消费者的自动回复机制，消费到了数据就自动回复，但是出现消费者还没处理完消息，就宕机了，但是mq以为你消费完成了。消费者重启了，mq推下一条消息，上一条消息丢失。
                方案：关掉autoAck，改成手动发送ack，每次消费完了，再去回复mq。
        
        2、kafka
            1）消费者出现消息丢失
                    方案：改成手动提交offset，每次消费完了，再手动提交，出现消息丢失，mq会再次发送上次未成功消费的消息。

            2）kafka出现消息丢失 
                    场景：这块比较常见的一个场景就是 kafka某个 broker宕机，然后重新选举 partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，
                            结果此时leader挂了，然后选举某个 follower成leader 之后，他不就少了一些数据?这就丢了一些数据啊。
                    方案：
                        所以此时一般是要求起码设置如下4个参数:
                        （1）给这个 topic 设置replication.factor 参数: 这个值必须大于1，要求每个 partition 必须有至少2个副本
                        （2）在kafka 服务端设置 mininsyncreplicas 参数: 这个值必须大于1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系
                        没掉队，这样才能确保 leader挂了还有一个 follower 吧
                        （3）在 producer 端设置acks=all: 这个是要求每条数据，必须是写入所有replica 之后，才能认为是写成功了
                        （4）在producer端设置retries=MAX;这个是要求一旦写入失败，就无限重试，卡在这里了。
                        
            3)生产者消息丢失
                    方案：如果按照上述的思路设置了 ack=all，一定不会丢，要求是，你的leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。
                            如果没满足这个条件，生产者会自动不断的重试，重试无限次
        3、如何保证mq消息的错乱的两场景
            先看看顺序会错乱的俩场景
                (1)rabbitmq:一个 queue，多个 consumer，这不明显乱了
                (2)kafka: 一个 topic，一个 partition，一个 consumer，内部多线程，这不也明显乱了

            那如何保证消息的顺序性呢?简单简单
                (1)rabbitmq: 拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点;或者就一个 queue 但是对应一个 consumer，然后这个 consumer内部用内存队列做排队，然后分发给底层不同的 worker来处理
                (2)kafka:一个 topic,一个 partition,一个 consumer,内部单线程消费,写N个内存 queue,然后单个线程分别消费一个内存 queue 即可
                        消费者端创建多个内存队列，具有相同key的数据都保存到同一个队列中，然后让每个线程分别消费一个内存
        4、mq的消息挤压
            方案：临时新建30个partition，将mq的数据消费写入到临时的30个partition里面，然后用30个消费者来消费，提高入库速度。
        5、如何解决消息队列的延时以及过期失效问题？
            方案：如果设置了过期时间，那么就批量重导，手动的发mq，手动的补偿。
        6、消息队列满了之后该怎么处理？
            同mq的消息挤压方案。或者快速丢掉数据，然后再批量重导，手动补偿。
        
    小结 
    既然MQ有优势也有劣势，那么使用MQ需要满足什么条件呢?
    ①生产者不需要从消费者处获得反馈。引入消息队列之前的直接调用,其接口的返回值应该为空,这才让明
    明下层的动作还没做，上层却当成动作做完了继续往后走，即所谓异步成为了可能。
    ②容许短暂的不一致性。
    ③确实是用了有效果。即解耦、提速、削峰这些方面的收益,超过加入MQ,管理MQ这些成本。

